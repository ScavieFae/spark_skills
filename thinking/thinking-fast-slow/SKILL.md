---
name: thinking-fast-slow
description: Kahneman's decision toolkit. Activate when evaluating forecasts, facing high-stakes choices, or when the room is too confident. Not bias trivia—operational moves for when intuition lies.
---

# Thinking, Fast and Slow

Your intuition is fast, confident, and systematically wrong in specific, predictable situations. This is about knowing which situations and what to do instead.

## The core insight

**Confidence is not a signal of accuracy.**

System 1—your fast, automatic brain—generates certainty based on *story coherence*, not *evidence quality*. Compelling narratives feel true. Missing information isn't flagged. The less you know, the easier everything fits.

The articulate, confident person in the room is not your best source of truth. Including yourself.

## When to slow down

- **Numbers are involved.** Intuition substitutes "how easily can I imagine this?" for "how likely is this?" These differ wildly.
- **You're forecasting.** Your brain projects from vivid scenarios, not base rates.
- **You feel very sure.** High confidence under time pressure is a warning.
- **Someone just anchored you.** The first number shapes all estimates after it.
- **It's your project.** Ownership biases toward optimism and risk-denial.

## When to trust intuition

Expert intuition works when:
- The environment is regular and predictable
- You've had extensive practice with immediate, clear feedback
- You've made this exact type of decision hundreds of times

Firefighter sensing a dangerous building: trust it. CEO sensing a market shift: skeptical. VC sensing which startup wins: basically noise with conviction.

The test: Has this person made this specific decision type many times, with fast accurate feedback on outcomes? If not, their confidence is just confidence.

## Before the decision

**Reference class forecasting**: Don't ask "how long will this take?" Ask "how long do projects like this typically take?"

Your inside view is optimistic. You know your special circumstances, your smart team, your unique approach. Every failed project had those too. Find the base rate. Start there.

**Premortem**: Imagine it's a year later and the thing failed badly. What happened?

This legitimizes doubt. It surfaces risks that "what could go wrong?" doesn't, because you've stipulated it *did* go wrong. Run it before the decision locks—after, motivated reasoning defends the choice.

## During the decision

**Counter the anchor**: If you heard a number before thinking, you're compromised. Ask: "What would I estimate if I'd never heard that?" Write it down before discussion.

**Seek disconfirmation**: What would have to be true for this to be wrong? If you can't answer, you don't understand your own reasoning.

**Check for WYSIATI (What You See Is All There Is)**: What information is missing? What didn't you look for because the answer already felt complete? Coherence is a warning—reality is messier.

**Separate evidence from story**: How many different stories could explain the same data? You're attached to the most convenient one.

## Evaluating forecasts

**Widen intervals**: If you think 3-6 months, it's probably 5-12. Professional forecasters underestimate uncertainty by 2-3x.

**Demand base rates**: "90% confidence on March delivery" means nothing without track record. What percentage of similar predictions were right?

**Discount detail**: Detailed plans feel more credible than vague ones. The world doesn't care. "Strategic partnerships and AI-driven insights" is narrative, not forecast.

## Managing others' biases

**Structure before preferences emerge**: Collect independent assessments in writing before group discussion. Post-commitment, motivated reasoning runs the show.

**Blind evaluation**: Remove identifying information. Your impression of the person colors assessment of the work.

**Criteria before options**: Agree on what matters before seeing choices. After, you'll weight criteria to justify your favorite.

**Name the bias without accusing**: "I notice we might be anchored—let's regenerate without that number" works. "You're anchored" is a fight.

## Loss aversion, briefly

Losses hurt roughly twice as much as equivalent gains feel good. This makes you:
- Risk-averse when protecting gains
- Risk-seeking when facing losses (desperate gambles to avoid locking in a loss)
- Overweight small probabilities when the stakes feel large

In negotiation and framing: whether something reads as gain or loss is malleable. Frame choices accordingly—for yourself and others.

## What this won't fix

Knowing about biases doesn't make you immune. They run on automatic processes that don't listen to lectures.

What helps:
- Decision processes that force slow thinking at key moments
- Checklists requiring specific questions
- Outside views from people not anchored to your framing
- Assuming you're overconfident and widening all estimates

You won't debias yourself through awareness. You might debias your decisions through structure.

## The discipline

Not about being smart. Smart people are worse—better at constructing convincing stories, more confidence in them.

The discipline is checking when you feel most sure. Running the premortem when excited. Finding the base rate when your inside view is vivid.

Your brain will call this overthinking. It's not. Slowing down costs little. Confident speed costs projects, forecasts, reversible decisions you didn't reverse.
