---
name: lean-startup
description: Ries's discipline for learning what to build before you build it. Activate when launching something new, when metrics aren't moving, when you're debating pivot-or-persevere, or when "we're doing lean" has become a way to avoid testing the scary hypothesis.
allowed-tools: Read, Edit, AskUserQuestion
---

# The Lean Startup

You're already doing lean. You have the Kanban board, the metrics dashboard, the two-week sprints. You run "experiments."

And yet—the experiments don't test anything scary. The metrics only go up. The process feels productive while nothing changes. You've turned validated learning into a way to avoid facing that your hypothesis might be wrong.

This is lean theater, and most startups are performing it.

The methodology exists to make you face the possibility that you're building something nobody wants—before it's too late. The framework is simple: Build-Measure-Learn. But the discipline is honesty, and honesty is rare.

---

## When to Use This

**You might be in lean theater if:**
- Your metrics can only go up (total users, cumulative revenue)
- You can't name your riskiest assumption
- The process feels productive but nothing's changing
- "We learned a lot" but you can't say what will be different
- "We need more data" has become a way to avoid deciding

**When designing something new:**
- You're figuring out what to actually test with an MVP
- You need to prioritize what to build first
- You're not sure what your riskiest assumption even is

**When the data's in and you're stuck:**
- You shipped and the numbers are ambiguous
- Someone asks "pivot or persevere?" and you don't have an answer
- You're explaining away results that didn't go the way you hoped

---

## The Principles

These apply to all modes. They're about learning, not process.

### The loop is the strategy

Build-Measure-Learn. Not "build, then eventually measure, then maybe learn." The loop is the unit of progress.

Every week you spend "getting ready to test" is a week your belief goes untested. The advantage of startups isn't resources—it's cycle time. How fast can you get through the loop?

Ship something. Measure something. Learn something. This week.

### Validated learning is the product

"We learned a lot" means nothing. Everyone learns a lot. You can learn a lot going bankrupt.

Validated learning means: you believed X, you tested X, and now you have evidence that changes what you do next.

"Customers want feature Y" is not validated—you learned they said they want it.
"We built Y and retention doubled" is validated—behavior changed.

The bar is high because self-deception is easy.

### The MVP tests the assumption, not the product

MVP has been diluted to mean "whatever we shipped first."

An MVP is the smallest thing that tests your riskiest assumption. Sometimes that's a landing page. Sometimes it's doing the service manually. Sometimes it's a conversation.

But **viable means viable**. If it's so broken customers bounce before you learn anything, you've learned nothing. You've confirmed that broken things don't work.

The question isn't "what's the least we can build?" It's "what's the fastest way to learn if we're wrong?"

### Vanity metrics lie

If a metric can only go up, it's vanity. Total users. Cumulative revenue. Aggregate anything.

These numbers feel good. They don't inform decisions.

Actionable metrics: retention by cohort, conversion rates, engagement frequency. Numbers that could go up or down. Numbers where the direction tells you something.

The test: if this metric dropped, would you do something different? If not, stop tracking it.

---

## When Activated

Determine the mode from context or by asking:

- **Loop mode** — "I'm designing what to build and test next"
- **Measure mode** — "I have data and I'm trying to understand what it means"
- **Pivot mode** — "Something isn't working and I need to decide what to do"

---

## Loop Mode: Designing the Experiment

You're about to build something. Let's make sure you're testing the right thing.

### The riskiest assumption

Before you build anything: what's the riskiest thing you believe?

Not "people will like it"—too vague. Specific beliefs:

- This problem is painful enough that people will pay to solve it
- They'll switch from their current solution
- They'll use it frequently enough to form a habit
- The person who benefits is the person who buys

Which belief, if wrong, makes everything else irrelevant? Test that first.

Most founders test execution risk ("can we build it?") when they should test market risk ("should we build it?"). You can build a beautiful product for a problem nobody has.

### Designing the MVP

For the riskiest assumption, design the smallest thing that tests it:

**1. What are you testing?**
State the hypothesis clearly. "We believe [customer segment] will [behavior] because [reason]."

**2. What's the minimum to learn?**
Not the minimum product—the minimum experiment. Could you test this with a landing page? A manual service? A conversation?

**3. What would success look like?**
Pick a number before you ship. Conversion rate, retention, engagement—something measurable. If you can't define success in advance, you'll rationalize any result.

**4. What would failure tell you?**
If the metric doesn't hit, what will you do differently? If the answer is "nothing," you're not running an experiment.

### The output

Before building, you should have:
- The riskiest assumption, stated clearly
- The MVP that tests it (not the product—the test)
- Success criteria, defined in advance
- What you'll do if it fails

---

## Measure Mode: Reading the Data

You've shipped. The data's in. Let's figure out what you've actually learned.

### The basic check

**1. What was the hypothesis?**

If you can't state what you were testing, you weren't running an experiment. You were just shipping.

**2. What did the data show?**

Not "how do you feel about the results." The numbers. Retention. Conversion. Engagement. Whatever you said you'd measure.

**3. Did you hit your success criteria?**

This is binary. Either you hit the number you defined in advance, or you didn't. If you didn't define a number, you can't answer this question—and you've learned nothing rigorous.

### The vanity check

For each metric you're tracking:

- **Can it go down?** If not, it's vanity.
- **Would a change drive a decision?** If not, stop tracking it.
- **Is it behavior or opinion?** Signups are behavior. NPS is opinion. Behavior wins.
- **Is it cohorted?** Aggregate numbers hide trends. Week-1 retention by cohort shows you reality.

### The learning

State what you learned in this format:

**We believed:** [hypothesis]
**We tested:** [what you shipped]
**We measured:** [specific metrics]
**We learned:** [what the data showed]
**We'll change:** [what you're doing differently]

If you can't fill in "We'll change," you haven't learned anything actionable. Go back to the data.

---

## Pivot Mode: The Hard Conversation

The thing isn't working. The metrics are flat. The hypothesis was wrong—or was it?

This is where most founders fail. Not from lack of framework. From lack of honesty.

### The diagnostic

**Are you explaining away results?**

Warning signs:
- "The metric didn't move, but we learned a lot"
- "It's an execution problem, not a strategy problem"
- "We need more time"
- "The early adopters aren't representative"

Maybe these are true. Or maybe you're bargaining with reality.

**What does the trend show?**

Not one data point—the trend. Are things getting better? Is each experiment moving the needle? If you've run three real tests and the line is flat, the hypothesis is probably wrong.

**Why are you still here?**

Honest question: Are you persevering because the evidence supports it, or because pivoting feels like failure?

Pivoting isn't giving up. Pivoting is admitting the strategy is wrong while the mission is still worth pursuing. The startup isn't the idea. Killing the idea isn't killing the company.

### The pivot types

If you decide to pivot, what kind?

- **Zoom-in pivot:** One feature becomes the product
- **Zoom-out pivot:** The product becomes one feature of something larger
- **Customer segment pivot:** Same product, different customers
- **Problem pivot:** Same customers, different problem
- **Channel pivot:** Same product, different route to customers
- **Value capture pivot:** Same product, different business model

Which type fits the evidence? What did you learn that points in a direction?

### The persevere case

Perseverance isn't default. It requires evidence:

- Each experiment is improving the metrics
- You have specific hypotheses for what will work next
- You can articulate why previous failures don't invalidate the strategy
- You're not just out of ideas for pivots

"We haven't given it enough time" is not a perseverance case. "We've seen X improve, we believe Y will improve next because Z" is.

### The output

After the conversation, you should know:

- **Pivot or persevere?** (decided, not deferred)
- **If pivot:** Which type, and what's the new hypothesis?
- **If persevere:** What's the next experiment, and what would change your mind?

---

## The Traps Beyond Theater

You've avoided lean theater. But the methodology has other failure modes.

### The vision trap

Some founders see something others don't. The data won't show it yet. Testing can sand off the edges that make it great.

This is real. And it's also the excuse every failed founder uses.

The question isn't "do you have conviction?" Everyone has conviction. The question is: why do you believe the data is wrong? Not "it's early"—why specifically? What do you see that the numbers can't capture?

If you can articulate it, you might be right. If you can't, you're probably in denial.

### The local maximum trap

You tested. You optimized. You found something that works.

But "works" might be a local maximum—safe, small, inoffensive. The thing that tests well with cautious early users isn't always the thing that wins the market.

Lean helps you avoid building something nobody wants. It doesn't automatically help you build something people love. Some products require a leap.

---

## The Honest Question

At any point, you should be able to answer:

**What's the riskiest thing you believe, and how are you testing it?**

If you can't answer that, you're doing theater.

The methodology exists for one purpose: facing the possibility that you're wrong—before it's too late. That's uncomfortable. It's supposed to be.
